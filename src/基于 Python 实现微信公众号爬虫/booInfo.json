{
  "err_no": 0,
  "err_msg": "success",
  "data": {
    "booklet": {
      "booklet_id": "6844733701339742216",
      "base_info": {
        "id": 0,
        "booklet_id": "6844733701339742216",
        "title": "基于 Python 实现微信公众号爬虫",
        "price": 1990,
        "category_id": "6809637769959178254",
        "status": 1,
        "user_id": "2260251606002765",
        "verify_status": 3,
        "summary": "爬虫基本原理、使用、抓包分析、存储数据、分析数据、数据可视化",
        "cover_img": "https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2017/12/18/160691fc2995dbf9~tplv-t2oaga2asx-image.image",
        "section_count": 11,
        "section_ids": "6844733701385879560|6844733701385895943|6844733701444599816|6844733701444599815|6844733701444616200|6844733701448794125|6844733701448794119|6844733701448794126|6844733701452988429|6844733701452988424|6844733701453004814|6844733701457182727",
        "is_finished": 1,
        "ctime": 1511357461,
        "mtime": 1630518534,
        "put_on_time": 1598288830,
        "pull_off_time": 1630518534,
        "finished_time": 1596106628,
        "recycle_bin_time": -62135596800,
        "verify_time": -62135596800,
        "submit_time": 1623752868,
        "top_time": -62135596800,
        "wechat_group_img": "https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/15867832528707d99befe9e71bcf702684563b440b605.jpg~tplv-t2oaga2asx-image.image",
        "wechat_group_desc": "四姐",
        "wechat_group_signal": "liuzhijun2131",
        "read_time": 0,
        "buy_count": 2745,
        "course_type": 1,
        "background_img": "",
        "is_distribution": 0,
        "distribution_img": "",
        "commission": 398,
        "can_vip_borrow": false,
        "is_sign": false
      },
      "reading_progress": {
        "id": 0,
        "booklet_id": "6844733701339742216",
        "user_id": "3210229681503629",
        "status": 1,
        "buy_type": 1,
        "reading_end": 0,
        "reading_progress": 0,
        "last_section_id": "0",
        "has_update": 1,
        "last_rtime": 1541860719,
        "ctime": 1541860719,
        "mtime": 1658224496,
        "valid_begin_time": 0,
        "valid_end_time": 0,
        "borrow_times": 0
      },
      "user_info": {
        "user_id": "2260251606002765",
        "user_name": "刘志军",
        "company": "",
        "job_title": "打杂の程序员",
        "avatar_large": "https://p6-passport.byteacctimg.com/img/user-avatar/8809c861d71c1a393440267279319468~300x300.image",
        "level": 4,
        "description": "公众号：Python之禅",
        "followee_count": 54,
        "follower_count": 12217,
        "post_article_count": 109,
        "digg_article_count": 128,
        "got_digg_count": 7592,
        "got_view_count": 321082,
        "post_shortmsg_count": 28,
        "digg_shortmsg_count": 4,
        "isfollowed": false,
        "favorable_author": 1,
        "power": 8412,
        "study_point": 0,
        "university": {
          "university_id": "0",
          "name": "",
          "logo": ""
        },
        "major": {
          "major_id": "0",
          "parent_id": "0",
          "name": ""
        },
        "student_status": 0,
        "select_event_count": 0,
        "select_online_course_count": 0,
        "identity": 0,
        "is_select_annual": false,
        "select_annual_rank": 0,
        "annual_list_type": 0,
        "extraMap": {},
        "is_logout": 0,
        "annual_info": [],
        "account_amount": 0,
        "user_growth_info": {
          "user_id": 2260251606002765,
          "jpower": 0,
          "jscore": 407.9,
          "jpower_level": 0,
          "jscore_level": 4,
          "jscore_title": "进阶掘友",
          "author_achievement_list": [],
          "vip_level": 0,
          "vip_title": ""
        },
        "is_vip": false
      },
      "event_discount": null,
      "is_buy": true,
      "section_updated_count": 11,
      "is_new": false
    },
    "introduction": {
      "id": 80700,
      "section_id": "6844733701385879560",
      "title": "介绍",
      "user_id": "2260251606002765",
      "booklet_id": "6844733701339742216",
      "status": 1,
      "content": "<h2>小册介绍</h2>\n<h3>为什么要学爬虫？</h3>\n<p>爬虫是一个非常具有实践性的编程技能，它并不是程序员的专属技能，任何具有一定编程基础的人都可以学习爬虫，写个爬虫分析一下股票走势，写个爬虫YouTube下载视频，上链家爬个房源数据分析房价趋势，爬知乎、爬豆瓣、爬新浪微博、爬影评，爬虫有太多可以做的事情，人工智能时代，对数据的依赖越来越重要。</p>\n<blockquote>\n<p>马云说：数据是新一轮技术革命最重要的生产资料。</p>\n</blockquote>\n<p>数据主要的来源就是通过爬虫获取，通过爬虫获取数据可以进行市场调研和数据分析，可以作为机器学习和数据挖掘的原始数据，我们通过微信公众号爬虫得到的数据对新媒体内容提供运营策略。</p>\n<p><img src=\"https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2017/12/27/16096069a668a0a3~tplv-t2oaga2asx-image.image\" alt=\"\"></p>\n<p>通过爬虫发现原来我4年前就在公众号写了文章，最近一年写了一百多篇，这些数据在微信平台是没法统计的，只有通过爬虫自己来统计分析。</p>\n<p><img src=\"https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2017/12/27/16093c99e7a08cd9~tplv-t2oaga2asx-image.image\" alt=\"\"></p>\n<p>对小白来说，爬虫可能是一个很复杂的事情，现在我们带着一个具体的目标（以爬虫微信公众号文章为例），在目标的驱动下，跟着这本小册一步一步学会爬虫，同时，那些所谓的前置知识也在这个过程中学会了。在这本小册中，我将以手把手的方式教会你如何进行网络爬虫。</p>\n<h3>为什么要学Python</h3>\n<p>Python 作为一门连小学生都可以学会的语言，非常适合没有编程基础的同学。它可以让你更快的理解编程的思想，能让你体会到通过编程来解决问题带来快乐，它没有复杂的语法，最为接近伪代码的语言，没有繁琐的编译过程，也不需要你手动管理内存，类库非常丰富，解决各种问题都有很多现成的工具，无需自己造轮子。</p>\n<blockquote>\n<p>Python之父说：人生苦短，我用Python。</p>\n</blockquote>\n<p><img src=\"https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2017/12/27/160963c415dfa3d1~tplv-t2oaga2asx-image.image\" alt=\"\"></p>\n<h3>你会学到什么？</h3>\n<ul>\n<li>爬虫基本原理</li>\n<li>爬虫工具 Requests 的基本使用</li>\n<li>数据抓包分析工具 Fiddler 的基本使用</li>\n<li>MongoDB 数据库的基本使用</li>\n<li>使用 Pandas 进行数据分析</li>\n<li>使用 Matplotlib 进行数据可视化展示</li>\n</ul>\n<h3>你需要准备什么？</h3>\n<p>任何对网络爬虫感兴趣者，或者是对微信公众号数据感兴趣的人都可以参与到这本小册中来，你需要准备的东西包括：</p>\n<ul>\n<li>一台移动设备（Android或者iOS手机）</li>\n<li>一个可登录的微信帐号</li>\n<li>一台可以联网的电脑</li>\n<li>还需要会一点点Python编程基础</li>\n</ul>\n<pre><code class=\"hljs language-!\">温馨提醒\n最后还是要声明一下，爬虫与反爬虫就像矛与盾，它们之间的较量是一场没有硝烟的战争，所以需要提醒广大爬友，爬取微信公众号文章数据过程中可能会受到微信服务器反爬虫机制的抵抗，虽然我没有遇到过明显地账号被限制的情况，但是我并不能保证你的微信号不会出现异常，在爬虫过程中，一定要控制好节奏，别惹怒了微信爸爸，为了保险起见，用小号进行测试爬虫是最安全的。\n</code></pre>\n<h2>作者介绍</h2>\n<p><img src=\"https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2017/12/27/160970f401e7bb36~tplv-t2oaga2asx-image.image\" alt=\"\">\n刘志军，Python 开发者，多年大型互联网公司工作经验，知乎 Python 话题活跃回答者，CSDN 公开课 讲师，在微信公众号「Python之禅」有4万+读者。</p>\n<h2>购买须知</h2>\n<ol>\n<li>本小册为图文形式内容服务，共计 11 节，上线时间为 2017 年 12 月 22 日；</li>\n<li>购买用户可享有小册永久的阅读权限；</li>\n<li>购买用户可进入小册微信群，与作者互动；</li>\n<li>掘金小册为虚拟内容服务，一经购买成功概不退款；</li>\n<li>掘金小册版权归北京北比信息技术有限公司所有，任何机构、媒体、网站或个人未经本网协议授权不得转载、链接、转贴或以其他方式复制发布/发表，违者将依法追究责任；</li>\n<li>在掘金小册阅读过程中，如有任何问题，请邮件联系 <a href=\"mailto:xiaoce@xitu.io\">xiaoce@xitu.io</a></li>\n</ol>",
      "draft_content": "",
      "draft_title": "介绍",
      "markdown_content": "",
      "markdown_show": "",
      "is_free": 1,
      "read_time": 193,
      "read_count": 0,
      "comment_count": 0,
      "ctime": 1511357461,
      "mtime": 1538477732,
      "is_update": 1,
      "draft_read_time": 0,
      "vid": "",
      "reading_progress": null
    },
    "sections": [
      {
        "id": 74870,
        "section_id": "6844733701385895943",
        "title": "微信公众号爬虫的基本原理",
        "user_id": "2260251606002765",
        "booklet_id": "6844733701339742216",
        "status": 1,
        "content": "",
        "draft_content": "",
        "draft_title": "微信公众号爬虫的基本原理",
        "markdown_content": "",
        "markdown_show": "",
        "is_free": 1,
        "read_time": 148,
        "read_count": 1536,
        "comment_count": 35,
        "ctime": 1513583957,
        "mtime": 1583400780,
        "is_update": 0,
        "draft_read_time": 0,
        "vid": "",
        "reading_progress": null
      },
      {
        "id": 74809,
        "section_id": "6844733701444599816",
        "title": "使用 Requests 实现一个简单网页爬虫",
        "user_id": "2260251606002765",
        "booklet_id": "6844733701339742216",
        "status": 1,
        "content": "",
        "draft_content": "",
        "draft_title": "使用 Requests 实现一个简单网页爬虫",
        "markdown_content": "",
        "markdown_show": "",
        "is_free": 1,
        "read_time": 1890,
        "read_count": 1374,
        "comment_count": 42,
        "ctime": 1512538447,
        "mtime": 1558026120,
        "is_update": 0,
        "draft_read_time": 0,
        "vid": "",
        "reading_progress": null
      },
      {
        "id": 74721,
        "section_id": "6844733701444599815",
        "title": "使用 Fiddler 抓包分析公众号请求过程",
        "user_id": "2260251606002765",
        "booklet_id": "6844733701339742216",
        "status": 1,
        "content": "",
        "draft_content": "",
        "draft_title": "使用 Fiddler 抓包分析公众号请求过程",
        "markdown_content": "",
        "markdown_show": "",
        "is_free": 0,
        "read_time": 370,
        "read_count": 684,
        "comment_count": 32,
        "ctime": 1511368005,
        "mtime": 1571280141,
        "is_update": 0,
        "draft_read_time": 0,
        "vid": "",
        "reading_progress": null
      },
      {
        "id": 74724,
        "section_id": "6844733701444616200",
        "title": "抓取微信公众号第一篇文章",
        "user_id": "2260251606002765",
        "booklet_id": "6844733701339742216",
        "status": 1,
        "content": "",
        "draft_content": "",
        "draft_title": "抓取微信公众号第一篇文章",
        "markdown_content": "",
        "markdown_show": "",
        "is_free": 0,
        "read_time": 510,
        "read_count": 520,
        "comment_count": 32,
        "ctime": 1511368243,
        "mtime": 1580573286,
        "is_update": 0,
        "draft_read_time": 0,
        "vid": "",
        "reading_progress": null
      },
      {
        "id": 74726,
        "section_id": "6844733701448794125",
        "title": "抓取微信公众号所有历史文章",
        "user_id": "2260251606002765",
        "booklet_id": "6844733701339742216",
        "status": 1,
        "content": "",
        "draft_content": "",
        "draft_title": "抓取微信公众号所有历史文章",
        "markdown_content": "",
        "markdown_show": "",
        "is_free": 0,
        "read_time": 352,
        "read_count": 396,
        "comment_count": 16,
        "ctime": 1511368284,
        "mtime": 1588581525,
        "is_update": 0,
        "draft_read_time": 0,
        "vid": "",
        "reading_progress": null
      },
      {
        "id": 74725,
        "section_id": "6844733701448794119",
        "title": "将爬取的文章存储到MongoDB",
        "user_id": "2260251606002765",
        "booklet_id": "6844733701339742216",
        "status": 1,
        "content": "",
        "draft_content": "",
        "draft_title": "将爬取的文章存储到MongoDB",
        "markdown_content": "",
        "markdown_show": "",
        "is_free": 0,
        "read_time": 367,
        "read_count": 299,
        "comment_count": 8,
        "ctime": 1511368269,
        "mtime": 1551342510,
        "is_update": 0,
        "draft_read_time": 0,
        "vid": "",
        "reading_progress": null
      },
      {
        "id": 74926,
        "section_id": "6844733701448794126",
        "title": "获取文章阅读数、点赞数、评论数、赞赏数",
        "user_id": "2260251606002765",
        "booklet_id": "6844733701339742216",
        "status": 1,
        "content": "",
        "draft_content": "",
        "draft_title": "获取文章阅读数、点赞数、评论数、赞赏数",
        "markdown_content": "",
        "markdown_show": "",
        "is_free": 0,
        "read_time": 741,
        "read_count": 322,
        "comment_count": 12,
        "ctime": 1514309251,
        "mtime": 1566270191,
        "is_update": 0,
        "draft_read_time": 0,
        "vid": "",
        "reading_progress": null
      },
      {
        "id": 74955,
        "section_id": "6844733701452988429",
        "title": "搭建数据分析环境：Anaconda、Jupyter Notebook",
        "user_id": "2260251606002765",
        "booklet_id": "6844733701339742216",
        "status": 1,
        "content": "",
        "draft_content": "",
        "draft_title": "搭建数据分析环境：Anaconda、Jupyter Notebook",
        "markdown_content": "",
        "markdown_show": "",
        "is_free": 0,
        "read_time": 284,
        "read_count": 290,
        "comment_count": 7,
        "ctime": 1515047534,
        "mtime": 1531899510,
        "is_update": 0,
        "draft_read_time": 0,
        "vid": "",
        "reading_progress": null
      },
      {
        "id": 74810,
        "section_id": "6844733701452988424",
        "title": "利用 Pandas 对爬取数据进行分析",
        "user_id": "2260251606002765",
        "booklet_id": "6844733701339742216",
        "status": 1,
        "content": "",
        "draft_content": "",
        "draft_title": "利用 Pandas 对爬取数据进行分析",
        "markdown_content": "",
        "markdown_show": "",
        "is_free": 0,
        "read_time": 786,
        "read_count": 285,
        "comment_count": 0,
        "ctime": 1512538790,
        "mtime": 1533372100,
        "is_update": 0,
        "draft_read_time": 0,
        "vid": "",
        "reading_progress": null
      },
      {
        "id": 74811,
        "section_id": "6844733701453004814",
        "title": "基于 Matplotlib 实现数据可视化展示",
        "user_id": "2260251606002765",
        "booklet_id": "6844733701339742216",
        "status": 1,
        "content": "",
        "draft_content": "",
        "draft_title": "基于 Matplotlib 实现数据可视化展示",
        "markdown_content": "",
        "markdown_show": "",
        "is_free": 0,
        "read_time": 524,
        "read_count": 303,
        "comment_count": 4,
        "ctime": 1512538800,
        "mtime": 1543932384,
        "is_update": 0,
        "draft_read_time": 0,
        "vid": "",
        "reading_progress": null
      },
      {
        "id": 74832,
        "section_id": "6844733701457182727",
        "title": "小结",
        "user_id": "2260251606002765",
        "booklet_id": "6844733701339742216",
        "status": 1,
        "content": "",
        "draft_content": "",
        "draft_title": "小结",
        "markdown_content": "",
        "markdown_show": "",
        "is_free": 0,
        "read_time": 28,
        "read_count": 150,
        "comment_count": 24,
        "ctime": 1512809373,
        "mtime": 1579163964,
        "is_update": 0,
        "draft_read_time": 0,
        "vid": "",
        "reading_progress": null
      }
    ]
  }
}